{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import math\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image arrays only when needed, too much memory to load everything on initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PASCALVOC(Dataset):\n",
    "    def __init__(self,textfile =\"train_val.txt\",transform = None):\n",
    "       # assert Path(rootfolder).exists(), \"%s is an invalid path\"%rootfolder\n",
    "\n",
    "        self.classes = ('__background__','aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                         'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                         'cow', 'diningtable', 'dog', 'horse',\n",
    "                         'motorbike', 'person', 'pottedplant',\n",
    "                         'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "        \n",
    "        self.sizes = (645,429,285)\n",
    "        self.all_img_names = []      \n",
    "        \n",
    "        self.rootfolder = \"C:\\\\Users\\\\bing.DEFIDE\\\\Documents\\\\VOCtrainval_11-May-2012\\\\VOCdevkit\\\\VOC2012\"\n",
    "\n",
    "        listofimages = \"C:\\\\Users\\\\bing.DEFIDE\\\\Documents\\\\VOCtrainval_11-May-2012\\\\VOCdevkit\\\\VOC2012\\\\ImageSets\\\\Main\\\\\" + textfile\n",
    "        \n",
    "        file = open(listofimages,\"r\")\n",
    "        for line in file:\n",
    "            self.all_img_names.append((line.split(\" \"))[0])  \n",
    "        file.close()\n",
    "\n",
    "            \n",
    "    def __getitem__(self,x):\n",
    "        imgname = self.all_img_names[x]\n",
    "        imagepath = self.rootfolder+ \"\\\\JPEGImages\\\\\" + imgname + \".jpg\"\n",
    "        annopath =  self.rootfolder+ \"\\\\Annotations\\\\\" + imgname + \".xml\"\n",
    "        \n",
    "        img = cv2.imread(imagepath)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        resize_shape = self.eulc_dist(img,imgname)\n",
    "        img = cv2.resize(img,(resize_shape,resize_shape))\n",
    "        \n",
    "        stepone = ET.parse(annopath)\n",
    "        steptwo = stepone.findall('object')\n",
    "        stepthree = steptwo[0].find('name')\n",
    "        label = stepthree.text\n",
    "\n",
    "        return (img,label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_img_names)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\"\n",
    "    \n",
    "    def eulc_dist(self,img,imgname): #calc eulc dist and return the size to reshape to\n",
    "        all_dist = []\n",
    "        for x in self.sizes:\n",
    "            vert_dist =  x - img.shape[0] \n",
    "            hori_dist = x - img.shape[1]\n",
    "            dist = math.sqrt((vert_dist*vert_dist) + (hori_dist*hori_dist))\n",
    "            all_dist.append(dist)\n",
    "        \n",
    "     #   if len(set(all_dist)) != len(self.sizes): #incase two exact same euclidean distances, which actually exists in pascal voc.. image res 314,400, equiv dist from 429 and 285\n",
    "      #      raise Exception(imgname + \" has two same euclidean distances computed\")\n",
    "        #in the event of equiv eucl dist, favor the larger number for now\n",
    "        idx_of_smallest = all_dist.index(min(all_dist))\n",
    "        return self.sizes[idx_of_smallest]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_RandomSampler(Sampler):\n",
    "    def __init__(self,data_src):\n",
    "        self.data_src = data_src\n",
    "        \n",
    "        self.len645 = None\n",
    "        self.len429 = None\n",
    "        self.len285 = None\n",
    "\n",
    "    def __iter__(self):     \n",
    "        \n",
    "        list645 = []\n",
    "        list429 = []\n",
    "        list285 = []\n",
    "        finallist = []\n",
    "        for x in range(len(self.data_src)):\n",
    "            if self.data_src[x][0].shape[1] == 645:\n",
    "                list645.append(x)\n",
    "            \n",
    "            elif self.data_src[x][0].shape[1] == 429:\n",
    "                list429.append(x)\n",
    "            \n",
    "            elif self.data_src[x][0].shape[1] == 285:\n",
    "                list285.append(x) \n",
    "        \n",
    "        \n",
    "        self.len645 = len(list645)\n",
    "        self.len429 = len(list429)\n",
    "        self.len285 = len(list285)\n",
    "        \n",
    "        shuffle(list645)\n",
    "        shuffle(list429)\n",
    "        shuffle(list285)\n",
    "        \n",
    "        if self.len645 != 0:\n",
    "            finallist.extend(list645)\n",
    "        if self.len429 != 0:\n",
    "            finallist.extend(list429)\n",
    "        if self.len285 !=0:\n",
    "            finallist.extend(list285)\n",
    "        return iter(finallist)\n",
    "    def __len__(self):\n",
    "        return len(self.data_src)\n",
    "        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_BatchSampler(Sampler):\n",
    "    def __init__(self,sampler,batch_size,drop_last = True):\n",
    "    #    if not isinstance(sampler, Sampler):\n",
    "     #       raise ValueError(\"sampler should be an instance of \"\n",
    "        #                     \"torch.utils.data.Sampler, but got sampler={}\"\n",
    "       #                      .format(sampler))\n",
    "     #   if not isinstance(batch_size, _int_classes) or isinstance(batch_size, bool) or \\\n",
    "      #          batch_size <= 0:\n",
    "        if not isinstance(batch_size, int) or batch_size <= 0:\n",
    "            raise ValueError(\"batch_size should be a positive integral value, \"\n",
    "                             \"but got batch_size={}\".format(batch_size))\n",
    "            \n",
    "        if drop_last != True:\n",
    "            raise Exception(\"drop_last input={} is invalid. Only drop_last = True is implemented for this function\".format(drop_last))\n",
    "        self.sampler = sampler\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch =[]\n",
    "        #slicing the list is probably easier and cleaner though and shouldnt take much memory\n",
    "        for count,value in enumerate(self.sampler):\n",
    "            #Assign only after calling sampler's iter method.\n",
    "            self.len645 = self.sampler.len645\n",
    "            self.len429 = self.sampler.len429\n",
    "            self.len285 = self.sampler.len285\n",
    "            \n",
    "            if count<self.len645:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch=[]\n",
    "            elif count == self.len645-1:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch =[]\n",
    "                else:\n",
    "                    batch = []\n",
    "                    continue\n",
    "            \n",
    "            elif self.len645<=count< self.len429 -1:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch =[]\n",
    "            elif count == self.len429 -1:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch =[]\n",
    "                else:\n",
    "                    batch =[]\n",
    "                    continue\n",
    "            \n",
    "            elif count>= self.len285:\n",
    "                batch.append(value)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "    \n",
    "\n",
    "    def __len__(self): \n",
    "        if self.drop_last:\n",
    "            length = (self.len645//self.batch_size) + (self.len429//self.batch_size) + (self.len285//self.batch_size)\n",
    "            return length\n",
    "        else: #not gonna use this option, not modifying\n",
    "            raise Exception(\"drop_last == False is not implemented for this function\")\n",
    "            #return (len(self.sampler) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi = PASCALVOC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm = Custom_RandomSampler(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm.len645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "drop_last input=False is invalid. Only drop_last = True is implemented for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-011aa33b04d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustom_BatchSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdrop_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-9943d5a313e1>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drop_last input={} is invalid. Only drop_last = True is implemented for this function\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: drop_last input=False is invalid. Only drop_last = True is implemented for this function"
     ]
    }
   ],
   "source": [
    "batch = Custom_BatchSampler(rdm,8,drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomSampler Len is called\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(x):\n",
    "    for x in range(x):\n",
    "        return x\n",
    "      #  print (type(x[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomSampler Init is called\n",
      "BatchSampler Init is called\n"
     ]
    }
   ],
   "source": [
    "traindata = DataLoader(hi,batch_sampler = Custom_BatchSampler(Custom_RandomSampler(hi),8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchSampler Iter is called\n",
      "RandomSampler Iter is called\n",
      "[tensor([[[[114,  98,  81],\n",
      "          [116,  99,  66],\n",
      "          [105,  87,  54],\n",
      "          ...,\n",
      "          [151, 130, 121],\n",
      "          [150, 136, 126],\n",
      "          [156, 149, 141]],\n",
      "\n",
      "         [[118,  94,  79],\n",
      "          [ 98,  83,  47],\n",
      "          [ 82,  58,  30],\n",
      "          ...,\n",
      "          [150, 131, 122],\n",
      "          [151, 138, 129],\n",
      "          [158, 151, 144]],\n",
      "\n",
      "         [[107,  90,  77],\n",
      "          [ 78,  55,  39],\n",
      "          [ 62,  34,  20],\n",
      "          ...,\n",
      "          [147, 131, 122],\n",
      "          [150, 139, 131],\n",
      "          [158, 151, 145]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[233, 174, 130],\n",
      "          [235, 175, 131],\n",
      "          [238, 178, 136],\n",
      "          ...,\n",
      "          [211, 121,  41],\n",
      "          [216, 124,  46],\n",
      "          [214, 122,  44]],\n",
      "\n",
      "         [[228, 174, 128],\n",
      "          [235, 181, 135],\n",
      "          [236, 180, 136],\n",
      "          ...,\n",
      "          [213, 122,  43],\n",
      "          [214, 122,  45],\n",
      "          [209, 117,  40]],\n",
      "\n",
      "         [[235, 172, 131],\n",
      "          [234, 171, 130],\n",
      "          [232, 168, 127],\n",
      "          ...,\n",
      "          [211, 118,  41],\n",
      "          [212, 119,  42],\n",
      "          [208, 115,  38]]],\n",
      "\n",
      "\n",
      "        [[[ 41,  61,   6],\n",
      "          [ 40,  62,   5],\n",
      "          [ 45,  68,   8],\n",
      "          ...,\n",
      "          [171, 151, 150],\n",
      "          [169, 149, 150],\n",
      "          [168, 148, 149]],\n",
      "\n",
      "         [[ 37,  56,   4],\n",
      "          [ 36,  57,   6],\n",
      "          [ 39,  60,   5],\n",
      "          ...,\n",
      "          [171, 152, 149],\n",
      "          [171, 152, 150],\n",
      "          [171, 152, 150]],\n",
      "\n",
      "         [[ 33,  51,   2],\n",
      "          [ 33,  51,   7],\n",
      "          [ 33,  53,   3],\n",
      "          ...,\n",
      "          [169, 152, 148],\n",
      "          [171, 153, 149],\n",
      "          [171, 154, 149]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 71,  76,  41],\n",
      "          [ 49,  64,  28],\n",
      "          [ 38,  50,  26],\n",
      "          ...,\n",
      "          [ 31,  34,  31],\n",
      "          [ 32,  33,  31],\n",
      "          [ 29,  30,  24]],\n",
      "\n",
      "         [[ 64,  68,  34],\n",
      "          [ 53,  65,  31],\n",
      "          [ 41,  52,  26],\n",
      "          ...,\n",
      "          [ 29,  33,  25],\n",
      "          [ 30,  33,  25],\n",
      "          [ 27,  30,  20]],\n",
      "\n",
      "         [[ 58,  61,  30],\n",
      "          [ 56,  66,  36],\n",
      "          [ 43,  53,  28],\n",
      "          ...,\n",
      "          [ 26,  32,  20],\n",
      "          [ 29,  35,  23],\n",
      "          [ 26,  32,  20]]],\n",
      "\n",
      "\n",
      "        [[[255, 255, 253],\n",
      "          [254, 255, 253],\n",
      "          [254, 255, 253],\n",
      "          ...,\n",
      "          [ 37,  39,  34],\n",
      "          [ 35,  37,  29],\n",
      "          [ 41,  45,  31]],\n",
      "\n",
      "         [[253, 255, 253],\n",
      "          [254, 255, 251],\n",
      "          [255, 254, 250],\n",
      "          ...,\n",
      "          [ 40,  39,  29],\n",
      "          [ 35,  36,  25],\n",
      "          [ 57,  59,  46]],\n",
      "\n",
      "         [[254, 253, 254],\n",
      "          [255, 254, 254],\n",
      "          [255, 255, 252],\n",
      "          ...,\n",
      "          [ 35,  38,  28],\n",
      "          [ 38,  43,  32],\n",
      "          [ 69,  76,  65]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 60,  69,  48],\n",
      "          [ 65,  70,  56],\n",
      "          [ 62,  66,  59],\n",
      "          ...,\n",
      "          [ 44,  50,  41],\n",
      "          [ 42,  49,  40],\n",
      "          [ 43,  50,  42]],\n",
      "\n",
      "         [[ 48,  46,  45],\n",
      "          [ 41,  40,  38],\n",
      "          [ 44,  44,  38],\n",
      "          ...,\n",
      "          [ 42,  48,  37],\n",
      "          [ 44,  50,  40],\n",
      "          [ 45,  52,  44]],\n",
      "\n",
      "         [[ 62,  62,  52],\n",
      "          [ 66,  66,  53],\n",
      "          [ 64,  67,  51],\n",
      "          ...,\n",
      "          [ 40,  46,  35],\n",
      "          [ 44,  49,  41],\n",
      "          [ 47,  52,  46]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 81, 168, 247],\n",
      "          [ 83, 170, 249],\n",
      "          [ 81, 168, 247],\n",
      "          ...,\n",
      "          [103, 166, 245],\n",
      "          [102, 165, 244],\n",
      "          [102, 165, 244]],\n",
      "\n",
      "         [[ 82, 167, 247],\n",
      "          [ 84, 170, 250],\n",
      "          [ 82, 168, 248],\n",
      "          ...,\n",
      "          [104, 167, 245],\n",
      "          [103, 166, 243],\n",
      "          [104, 166, 245]],\n",
      "\n",
      "         [[ 84, 168, 248],\n",
      "          [ 86, 170, 250],\n",
      "          [ 85, 169, 249],\n",
      "          ...,\n",
      "          [108, 171, 248],\n",
      "          [106, 169, 246],\n",
      "          [105, 168, 246]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[245, 240, 237],\n",
      "          [242, 236, 236],\n",
      "          [243, 237, 238],\n",
      "          ...,\n",
      "          [165, 152, 161],\n",
      "          [163, 150, 158],\n",
      "          [167, 153, 160]],\n",
      "\n",
      "         [[246, 241, 238],\n",
      "          [243, 237, 237],\n",
      "          [242, 236, 237],\n",
      "          ...,\n",
      "          [166, 153, 163],\n",
      "          [155, 142, 151],\n",
      "          [150, 137, 146]],\n",
      "\n",
      "         [[246, 241, 238],\n",
      "          [243, 237, 237],\n",
      "          [241, 235, 236],\n",
      "          ...,\n",
      "          [165, 152, 161],\n",
      "          [156, 144, 154],\n",
      "          [152, 140, 150]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  1,   1,   1],\n",
      "          [  1,   2,   2],\n",
      "          ...,\n",
      "          [ 83,  69,  60],\n",
      "          [ 83,  69,  60],\n",
      "          [ 83,  69,  60]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  1,   2,   1],\n",
      "          [  0,   1,   2],\n",
      "          ...,\n",
      "          [ 84,  70,  61],\n",
      "          [ 84,  70,  61],\n",
      "          [ 84,  71,  62]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  1,   1,   1],\n",
      "          [  1,   2,   3],\n",
      "          ...,\n",
      "          [ 82,  69,  59],\n",
      "          [ 83,  69,  60],\n",
      "          [ 83,  69,  60]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  5,   5,   3],\n",
      "          [  6,   6,   5],\n",
      "          [  5,   5,   3],\n",
      "          ...,\n",
      "          [166, 164, 165],\n",
      "          [166, 164, 165],\n",
      "          [165, 163, 164]],\n",
      "\n",
      "         [[  4,   4,   2],\n",
      "          [  6,   6,   4],\n",
      "          [  5,   5,   3],\n",
      "          ...,\n",
      "          [166, 164, 165],\n",
      "          [165, 163, 164],\n",
      "          [164, 162, 163]],\n",
      "\n",
      "         [[  3,   3,   1],\n",
      "          [  5,   5,   3],\n",
      "          [  3,   3,   1],\n",
      "          ...,\n",
      "          [165, 163, 164],\n",
      "          [165, 163, 164],\n",
      "          [165, 163, 164]]],\n",
      "\n",
      "\n",
      "        [[[246, 254, 255],\n",
      "          [246, 254, 255],\n",
      "          [246, 254, 255],\n",
      "          ...,\n",
      "          [241, 255, 255],\n",
      "          [241, 255, 255],\n",
      "          [241, 255, 255]],\n",
      "\n",
      "         [[246, 254, 255],\n",
      "          [246, 254, 255],\n",
      "          [246, 254, 255],\n",
      "          ...,\n",
      "          [241, 255, 255],\n",
      "          [241, 255, 255],\n",
      "          [241, 255, 255]],\n",
      "\n",
      "         [[246, 254, 255],\n",
      "          [246, 254, 255],\n",
      "          [246, 254, 255],\n",
      "          ...,\n",
      "          [241, 255, 255],\n",
      "          [241, 255, 255],\n",
      "          [241, 255, 255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 91,  91, 102],\n",
      "          [ 96,  95,  97],\n",
      "          [107, 102,  98],\n",
      "          ...,\n",
      "          [115, 119, 128],\n",
      "          [110, 115, 127],\n",
      "          [105, 111, 127]],\n",
      "\n",
      "         [[ 85,  89,  93],\n",
      "          [ 88,  87,  93],\n",
      "          [104,  98, 105],\n",
      "          ...,\n",
      "          [134, 140, 159],\n",
      "          [122, 130, 146],\n",
      "          [126, 136, 150]],\n",
      "\n",
      "         [[101, 101,  95],\n",
      "          [107, 106, 118],\n",
      "          [114, 115, 128],\n",
      "          ...,\n",
      "          [132, 140, 152],\n",
      "          [133, 142, 158],\n",
      "          [125, 136, 156]]]], dtype=torch.uint8), ('person', 'pottedplant', 'train', 'train', 'boat', 'bus', 'tvmonitor', 'bus')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
