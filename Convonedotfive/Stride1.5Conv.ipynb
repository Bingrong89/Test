{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create intermediate map, for convolution with stride 1.5 \n",
    "### Idea is to create a corresponding tensor containing all the convolution inputs that would occur in a stride 1.5 convolution, then processing this tensor with a normal convolution where stride = kernel size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only even multiples of 1.5 end in integers. So filters must convolve odd(1(zero indexed position) + even times across height & width) times along height and width  \n",
    "Along output map HxW(1-indexed):  \n",
    "If index H or W == even, outmap will contain combined pixel pairs +1  \n",
    "i.e (1,1) 0 pair(raw input)  \n",
    "    (1,2) 1 pair(along 2nd dimension)  \n",
    "    (2,2) 2 pairs(along both dimensions)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\frac{3n-3}{1.5} + 1  \\\\\n",
    "= \\frac {3(n-1)}{0.5(3)} + 1  \\\\\n",
    "= 2(n-1)+1 \\\\\n",
    "= 2n-2+1 \\\\\n",
    "= 2n-1 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For all integers n > 0, 2n-1 always gives positive odd numbers(for H ^ W), where stride = 1.5 and filter size = 3 and input size is multiple of 3\n",
    "#### But not all odd numbers are multiples of 3.. :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make cheaper one\n",
    "The output from better_compute is meant to run with dilated convolution, dilation = 1\n",
    "Refer to ** https://ezyang.github.io/convolution-visualizer/index.html ** for visualization\n",
    "The output from better_compute passed into a convolution layer with kernel size 3, dilation 2, stride 3, is equivalent to a stride 1.5 convolution with kernel size 3 on the input into better_compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final version. Decent speed for forward and backward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_compute3(input_mtx,filtersize = 3):\n",
    "    #use with dilated convolution\n",
    "    #used to output intermediate, then convolve with dilated convolution to effect stride 1.5 on input\n",
    "    stride=1.5 # algorithm only works for stride value 1.5\n",
    "\n",
    "    assert input_mtx.dim()==4,\\\n",
    "    \"Input tensor dimension is %dD instead of 4D\" %input_mtx.dim()\n",
    "  \n",
    "    batchsize = input_mtx.size()[0]\n",
    "    channels = input_mtx.size()[1]\n",
    "    input_rows = input_mtx.size()[2] #height\n",
    "    input_cols = input_mtx.size()[3] #width\n",
    "    \n",
    "    rows = ((input_rows-filtersize)/stride)+1 #output H dimension\n",
    "    columns = ((input_cols-filtersize)/stride)+1 #output W dimension\n",
    "    assert rows%1 == 0 and columns%1 ==0,\\\n",
    "    \"Invalid output HxW dimension, current output dimension for HxW is %f x %f\" %(rows,columns) #safety check\n",
    "    \n",
    "    new_rows = (2*input_rows)-1 #itm H dimension\n",
    "    new_cols =  (2*input_cols)-1 #itm W dimension\n",
    "    \n",
    "    itm1 = torch.zeros(input_rows,new_cols,device=device,requires_grad=False)\n",
    "    itm2 = torch.zeros(new_rows,new_cols,device=device,requires_grad=False)\n",
    "    output2 = torch.zeros(batchsize,channels,new_rows,new_cols,device=device,requires_grad=False)\n",
    "    \n",
    "    for batch in range(batchsize):\n",
    "        for chl in range(channels):\n",
    "            itm1[:,::2] = input_mtx[batch][chl][:,::1] #fill in alternating columns\n",
    "            itm1[:,1:-1:2] = (itm1[:,0:-1:2] +itm1[:,2:new_rows:2])/2     #calculate inbetween column values\n",
    "            itm2[::2,:] = itm1[::1,:] #fill in alternating rows\n",
    "            itm2[1:-1:2,:] = (itm2[0:-1:2,:] + itm2[2:new_cols:2,:])/2 #calculate inbetween row values\n",
    "            output2[batch][chl] = itm2\n",
    "        \n",
    "    return output2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[0][0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = torch.randn(2,3,645,645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = better_compute3(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4531, -0.4318, -0.4105,  ...,  0.2111,  0.6557,  1.1003],\n",
       "        [-1.0493, -0.1889,  0.6715,  ...,  0.5747,  0.5519,  0.5291],\n",
       "        [-1.6455,  0.0540,  1.7534,  ...,  0.9383,  0.4481, -0.0421],\n",
       "        ...,\n",
       "        [-1.3671, -0.4934,  0.3803,  ...,  0.2874, -0.2618, -0.8110],\n",
       "        [-0.3200,  0.3399,  0.9997,  ..., -0.0308, -0.4580, -0.8852],\n",
       "        [ 0.7272,  1.1731,  1.6191,  ..., -0.3490, -0.6542, -0.9595]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conx = nn.Conv2d(64,10,3,3,dilation=2)\n",
    "out1 = conx(small)\n",
    "out = out1.view(1,-1)\n",
    "del out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(2140*214,10)\n",
    "out  = lin(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conx.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeone = torch.tensor([[1,1,1,2,2,2]],dtype=torch.float,requires_grad=True)\n",
    "typetwo = torch.tensor([[3,3,3,4,4,4]],dtype=torch.float,requires_grad=True)\n",
    "testinput = torch.cat((typeone,typeone,typeone,typetwo,typetwo,typetwo),0)\n",
    "filter2 = torch.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = testinput.view(1,1,6,6)\n",
    "itmnew = torch.zeros(1,1,11,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newx = new.view(6,6)\n",
    "itmnewx = torch.zeros(11,6)\n",
    "itmnewx2 = torch.zeros(11,11)\n",
    "itmnewx[::2,:] = newx\n",
    "itmnewx2[:,::2] = itmnewx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
